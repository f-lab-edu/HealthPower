# 활성화할 프로파일을 명확하게 지정
spring:
  profiles:
    active: prod # 실행 시 필요에 따라 prod, dev, local 변경

---
# 모든 프로파일에 공통으로 적용되는 기본 설정
spring:
  application:
    name: HealthPower
  mvc:
    locale: ko_KR
    locale-resolver: fixed
    hiddenmethod:
      filter:
        enabled: true
  thymeleaf:
    prefix: classpath:/templates/
    suffix: .html
  jpa:
    hibernate:
      ddl-auto: update
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
    show-sql: true
    properties:
      hibernate:
        format_sql: true
  session:
    store-type: redis
  kafka:
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: com.example.infra.kafka
        spring.json.value.default.type: com.example.infra.kafka.CouponIssuedEvent
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB
      max-request-size: 10MB
  http:
    encoding:
      force: true
      charset: UTF-8
      enabled: true
  server:
    port: 8080 # 모든 프로파일에 적용되는 기본 포트
  management:
    endpoints:
      web:
        base-path: /actuator # 모든 프로파일에 적용되는 Actuator 기본 경로
        exposure:
          include: health # 모든 프로파일에서 기본적으로 health 엔드포인트 노출

jwt:
  secret: "cG93ZXJwb3dlcnRlc3RoZWFsdGhwb3dlcnRoZXN0cG93ZXI="
toss:
  secret: "test_sk_6BYq7GWPVvnRvyQgxoMwVNE5vbo1"
  client: "test_gck_docs_Ovk5rk1EwkEbP0W43n07xlzm"
cloud:
  aws:
    region:
      static: ap-northeast-2
    stack:
      auto: false
slack:
  webhook:
    url: https://hooks.slack.com/services/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
logging:
  level:
    org.springframework.web.socket: DEBUG
    org.springframework.messaging.simp: DEBUG

---
# local 프로파일 설정 (로컬 개발 환경용)
spring:
  config:
    activate:
      on-profile: local
  datasource:
    url: jdbc:mysql://localhost:3306/springJWT?useSSL=false&useUnicode=true&serverTimezone=Asia/Seoul&allowPublicKeyRetrieval=true
    username: root
    password: 1234
    driver-class-name: com.mysql.cj.jdbc.Driver
  data:
    redis:
      host: localhost
      port: 6379
  kafka:
    bootstrap-servers: localhost:9092
  cloud:
    aws:
      credentials:
        access-key: ""
        secret-key: ""
      s3:
        bucket: healthpowerbucket
  app:
    upload:
      dir: C:/Users/JJS/Downloads
management:
  endpoints:
    web:
      exposure:
        include: health,info
  endpoint:
    health:
      show-details: always
logstash:
  host: localhost
  port: 5000

---
# dev 프로파일 설정 (개발 서버 환경용)
spring:
  config:
    activate:
      on-profile: dev
  datasource:
    url: ${DB_LOCAL_URL}
    username: root
    password: 1234
  data:
    redis:
      host: localhost # Docker Compose가 아닌 로컬 개발 환경을 상정
      port: 6379
  kafka:
    bootstrap-servers: kafka:9092 # Docker Compose 컨테이너 이름을 사용
  cloud:
    aws:
      credentials:
        access-key: ${AWS_ACCESS_KEY:}
        secret-key: ${AWS_SECRET_KEY:}
      s3:
        bucket: ${AWS_S3_BUCKET:dev-default-bucket}
  jwt:
    secret: ${JWT_SECRET}
  toss:
    secret: ${TOSS_SECRET}
  app:
    upload:
      dir: /home/ubuntu/uploads
  management:
    endpoints:
      web:
        exposure:
          include: health,info
  endpoint:
    health:
      show-details: always
  slack:
    webhook:
      url: ${SLACK_WEBHOOK_URL}
  logstash:
    host: localhost
    port: 5000

---
# prod 프로파일 설정 (운영 서버 환경용)
spring:
  config:
    activate:
      on-profile: prod
  datasource:
    url: ${DB_URL}
    username: ${DB_USERNAME}
    password: ${DB_PASSWORD}
  data:
    redis:
      host: redis # Docker Compose 환경에서 Redis 컨테이너 이름
      port: 6379
  kafka:
    bootstrap-servers: kafka:9092 # Docker Compose 환경에서 Kafka 컨테이너 이름
  cloud:
    aws:
      credentials:
        access-key: ${AWS_ACCESS_KEY}
        secret-key: ${AWS_SECRET_KEY}
      s3:
        bucket: ${AWS_S3_BUCKET}
  jwt:
    secret: ${JWT_SECRET}
  toss:
    secret: ${TOSS_SECRET}
  client: ${TOSS_CLIENT}
  management:
    endpoints:
      web:
        exposure:
          include: health,info,prometheus
    endpoint:
      health:
        show-details: always
      prometheus:
        enabled: true
  slack:
    webhook:
      url: ${SLACK_WEBHOOK_URL}
  app:
    upload:
      dir: /home/ubuntu/uploads
  logstash:
    host: logstash
    port: 5000
